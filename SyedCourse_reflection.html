<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Course Learning Reflections</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        h3 {
            margin-top: 20px;
        }
        ul {
            margin: 10px 0;
            padding-left: 20px;
        }
        li {
            margin: 5px 0;
        }
        strong {
            color: #34495e;
        }
    </style>
</head>
<body>
    <h1><strong>Course Learning Reflections</strong></h1>
    <div>
        <h3>1. Problems in Nature</h3>
        <ul>
            <li><strong>Iteration:</strong> Water droplets falling repeatedly in a stream, patterns formed by repetitive waves.</li>
            <li><strong>Recursion:</strong> Branching of trees or rivers, where the structure repeats at smaller scales.</li>
            <li><strong>Backtracking:</strong> Ants searching for food, solving mazes.</li>
        </ul>

        <h3>2. Space and Time Efficiency</h3>
        <p><strong>Definitions:</strong></p>
        <ul>
            <li><strong>Space Efficiency:</strong> Extra memory (space) used during execution.</li>
            <li><strong>Time Efficiency:</strong> How fast a program completes its execution.</li>
        </ul>
        <p><strong>Importance:</strong> Handles larger inputs without excessive resources, saving on computational costs.</p>

        <h3>3. Classes of Problems</h3>
        <ul>
            <li><strong>Decomposition</strong></li>
            <li><strong>Pattern Recognition</strong></li>
            <li><strong>Abstraction</strong></li>
            <li><strong>Brave and Cautious Travel</strong></li>
            <li><strong>Pruning</strong></li>
            <li><strong>Lazy Propagation Evaluation</strong></li>
            <li><strong>Sliding Window</strong></li>
            <li><strong>Level Order Traversal</strong></li>
            <li><strong>Hierarchical Data</strong></li>
            <li><strong>Edge Relaxation</strong></li>
            <li><strong>Balancing and Rotations</strong></li>
            <li><strong>Kleene Closure</strong></li>
            <li><strong>Pre-Computing</strong></li>
            <li><strong>Parental Dominance</strong></li>
            <li><strong>Prefix and Suffix</strong></li>
            <li><strong>Partitioning</strong></li>
            <li><strong>Bit Manipulations</strong></li>
            <li><strong>Memoization</strong></li>
            <li><strong>Invariants</strong></li>
            <li><strong>Shortest Path Trees</strong></li>
        </ul>

        <h3>4. Order of Growth</h3>
        <ul>
            <li><strong>O(n!):</strong> Grows explosively (brute-force).</li>
            <li><strong>O(3^n):</strong> Exponential growth with base 3 (combinatorial problems).</li>
            <li><strong>O(2^n):</strong> Exponential growth with base 2 (recursive problems).</li>
            <li><strong>O(n^3):</strong> Polynomial growth (cubic-time algorithms).</li>
            <li><strong>O(n^2):</strong> Quadratic growth (Bubble Sort).</li>
            <li><strong>O(nlogn):</strong> Sub-quadratic growth (divide-and-conquer algorithms).</li>
            <li><strong>O(n):</strong> Linear growth (single-loop algorithms).</li>
            <li><strong>O(root(n)):</strong> Sub-linear growth (e.g., finding factors).</li>
            <li><strong>O(logn):</strong> Logarithmic growth (divide-and-conquer strategies).</li>
        </ul>

        <h3>5. Tree Data Structures</h3>
        <ul>
            <li><strong>Tree:</strong> Simple and memory efficient.</li>
            <li><strong>Binary Search Tree (BST):</strong> Used for sorting, may create skewness.</li>
            <li><strong>2-3 Tree:</strong> Reduces skewness by storing more than one element per node.</li>
            <li><strong>AVL Tree:</strong> Balances through rotations, but may become complex.</li>
            <li><strong>Red-Black Tree:</strong> Reduces rotations.</li>
            <li><strong>Heap:</strong> Priority queues, dynamic memory allocation.</li>
            <li><strong>Trie:</strong> Optimized for strings, where paths represent characters.</li>
        </ul>

        <h3>6. Array Query Algorithms</h3>
        <p><strong>Applications:</strong> Used in competitive programming and real-world systems for performance-critical queries on large datasets.</p>
        <p><strong>Principles:</strong> Divide and conquer, preprocessing.</p>
        <ul>
            <li><strong>Segment Trees:</strong> O(logn) complexity for range queries and updates.</li>
            <li><strong>Fenwick Trees:</strong> O(logn) complexity with lower memory overhead.</li>
            <li><strong>Sparse Table:</strong> O(1) query time after O(nlogn) preprocessing.</li>
        </ul>

        <h3>7. Trees vs. Graphs</h3>
        <p><strong>Traversal:</strong></p>
        <ul>
            <li><strong>Trees:</strong> Pre-order, In-order, Post-order.</li>
            <li><strong>Graphs:</strong> DFS, BFS.</li>
        </ul>
        <p><strong>Key Differences:</strong></p>
        <ul>
            <li><strong>Trees:</strong> Hierarchical structure, no cycles.</li>
            <li><strong>Graphs:</strong> Generalized structure, can have cycles.</li>
        </ul>
        <p><strong>Applications:</strong></p>
        <ul>
            <li><strong>Trees:</strong> File systems, organizational charts, decision trees.</li>
            <li><strong>Graphs:</strong> Social networks, road maps, network analysis.</li>
        </ul>

        <h3>8. Sorting and Searching Algorithms</h3>
        <ul>
            <li><strong>Sorting Algorithms:</strong>
                <ul>
                    <li><strong>Bubble Sort:</strong> O(n²) worst case.</li>
                    <li><strong>Selection Sort:</strong> O(n²).</li>
                    <li><strong>Insertion Sort:</strong> O(n²) worst case, O(n) best case.</li>
                    <li><strong>Merge Sort:</strong> O(nlogn).</li>
                    <li><strong>Quick Sort:</strong> O(n²) worst case, O(nlogn) average case.</li>
                    <li><strong>Heap Sort:</strong> O(nlogn).</li>
                </ul>
            </li>
            <li><strong>Searching Algorithms:</strong>
                <ul>
                    <li><strong>Boyer-Moore Algorithm:</strong> O(nm) worst case, O(n) best case.</li>
                    <li><strong>Knuth-Morris-Pratt (KMP) Algorithm:</strong> O(n + m).</li>
                    <li><strong>Rabin-Karp Algorithm:</strong> O(nm) worst case, O(n + m) average case.</li>
                </ul>
            </li>
            <li><strong>Graph Searching Algorithms:</strong>
                <ul>
                    <li><strong>Dijkstra's Algorithm:</strong> O(V²) with adjacency matrix, O(E + VlogV) with priority queue.</li>
                    <li><strong>Kruskal's Algorithm:</strong> O(E logE).</li>
                    <li><strong>Prim's Algorithm:</strong> O(V²) with adjacency matrix, O(E + VlogV) with priority queue.</li>
                    <li><strong>Floyd-Warshall Algorithm:</strong> O(V³).</li>
                    <li><strong>Warshall's Algorithm:</strong> O(V³).</li>
                </ul>
            </li>
        </ul>
    </div>
</body>
</html>
